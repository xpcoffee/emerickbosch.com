---
title: Inexpensive mechanisms to support team processes
description: A list of mechanisms that are cheap to implement, but that empower valuable processes.
faIcon: faPaperclip
date: 2021-09-02
---

import { ExpandableSection } from "../components/expandableSection"

This is a (hopefully) growing of mechanisms that are cheap to practically implement, but that empower processes
that add value to the team and our customers.

<ExpandableSection 
initiallyHidden={true}
header="Tenets"
description="A prioritized set of team defaults for how to resolve tension between incompatible requirements.">

**What does this promote?**

Fast decision making in ambiguous situations / agreement within the team about what's important / communication to stakeholders about team priorities.

**When do you use it?**

For every large initiative e.g. a team or a project.

**Why is it useful?**

The exercise of deciding on tenets helps align the team on what we think the difficult tradeoffs of our space are and around the core value we mean to deliver.

The tenets themselves can be consulted whenever we reach a potentially difficult set of tradeoffs and helps frame the discussion in terms of what the team
previously agreed upon; the goal is to help make decisions quickly and in a way that's consistent with the team's goals/prior decisions.

The tenets also help remove ambiguity for team members when prioritizing tasks and provide a clear team stance on what's considered important to stakeholders.

**Considerations**

Tenets are _highly_ context dependent and change over time, as requirements and the team evolves. They need to be actively referenced and frequently updated.

Tenets must also address hard questions; their use at helping guide difficult tradeoffs is highly diminished if they don't project a strong opinion.

**Examples**

```md
Team: API platform team

Tenets:

1.  Force multiplication over individual attention. We maximize our value by delivering on features that benefit the most amount of teams on the platform.
1.  General availability over individual availability. We protect the overall experience of the APIs on the platform; we will deteriorate the experience of
    individual APIs if their performance starts to affect other APIs.
1.  Developer experience over feature set. We first build and iterate on the experience such that it is safe and easy to integrate with before we consider additional features.
```

```md
Project: Address imminent scaling cliff

Tenets:

1.  Security over availability. We do not regress on our security posture, even if we end up hitting our scaling cliff.
1.  Results over perfection. The primary goal is to prevent our service from hitting the scaling cliff, even if that means taking on technical debt.
1.  Early warning over maximum output. We instrument our service to detect early signs of reaching the scaling cliff. We accept the risk of dropping
    potential weeks of output up-front in favour of having the ability to detect critical failure and subsequently react to (escalate to more teams/change tactic).
```

</ExpandableSection>

<ExpandableSection 
initiallyHidden={true}
header="Tech experiment"
description="A short-lived task aimed at gaining new information.">

**What does this promote?**

Innovation / creativity / getting out of analysis paralysis.

**When do you use it?**

When you have technical ambiguity where you are unsure about the right path forward.
OR when you have a team member that is curious to learn about/play with technology.

**Why is it useful?**

It provides space for a task that can fail, while ensuring that we extract value out of it.

**What does it look like?**

This is a template for an experiment proposal/overview. This is used to make the initial decision around
whether or not to plan the experiment.

```md
# Experiment: Foobar

## Context

How do things work now?

## Ambiguity/problem

What knowledge are we aiming to gain/what problem are we looking to solve with this experiment?

## Approach

Short description of the approach. This is not a design; that will come later.

## Out of scope

What will not be considered as part of this experiment.

## Success criteria/Metrics

How do we know whether this was successful or not?

## Owners

@someone
@anyone

## Start date

YYYY-MM-DD

## End date

YYYY-MM-DD

This is a hard cutoff. On this date we make a decision around failure/success and whether to invest further.

## Conclusions/learnings

To be written after the experiment to summaries the outcomes. Link to more detailed artifacts here (designs, data, code, etc).
```

</ExpandableSection>

<ExpandableSection 
initiallyHidden={true}
header="Operational event log"
description="Team-specific log of start/end of significant operational events. Most recent entries at the top.">

**What does this promote?**

Knowledge sharing on operational events / historical records of operational events / data gathering of operational events / data analysis of operational events / event response analysis / correlation of events.

**When do you use it?**

After every event concludes or after investigations.

**Why is this useful?**

Can be referenced by other teams during their reviews. Can be ingested into dashboards to auto-generate annotations. Can
be processed for insights (recurring issues; average time to mitigation).

**What does it look like?**

```md
# Operational events

2021-08-30T10:14Z | home page latency increase | end | _ticket link_ | full recovery
2021-08-30T10:13Z | home page latency increase | state-change | _ticket link_ | partial recovery
2021-08-30T10:11Z | home page latency increase | start | _ticket link_ | alarm fires
2021-08-29T12:00Z | failover data migration | end | _ticket link_ | workflow successful
2021-08-29T09:31Z | failover data migration | start | _ticket link_ | workflow started
```

</ExpandableSection>

<ExpandableSection 
initiallyHidden={true}
header="Operational review journal"
description="Team-specific journal of a periodic operational review.">

**What does this promote?**

Knowledge sharing on operational events / historical records of operational events / data gathering of operational events / data analysis of operational events / record of operational issues / record of operational decisions.

**When do you use it?**

Every operational review session.

**Why is it useful?**

Record of the review for tracking, knowledge-sharing, reference and long-term trend analysis.

```md
# YYYY-MM-DD Ops review

## What experiences do we own/maintain?

_This section shouldn't change often and is more to allow sharing._

## Operational wins

## What was last week like for customers?

Customer impacting events (both good and bad):

Customer feedback:

Metrics callouts:

## What was last week like for on-call?

Major events:

Notable classes of issues:

Lessons learned:

Most wanted improvement:

## What is currently the biggest operational risk?

## Action items

1. Action item - @owner
```

</ExpandableSection>
